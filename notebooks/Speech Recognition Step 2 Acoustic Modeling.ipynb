{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Overview of Speech Recognition\n",
    "## 1.1 Hidden Markov Model for Accoustic Modeling\n",
    "As speech is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Hidden Markov Model for Accoustic Modeling\n",
    "## Phoneme model of words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Gaussian Mixture Model\n",
    "## Overview\n",
    "\n",
    "\n",
    "+ **Mixture of Gaussians**\n",
    "$$p(x) = \\sum_{k=1}^{K} \\pi_{k}N(x|\\mu_{k}, \\Sigma_{k})$$\n",
    "> + Add a hidden variable Z, which is like a swith to each Gaussian\n",
    "  $$p(Z) = \\prod_{k=1}^{K} \\pi_{k}^{z_{k}}$$\n",
    "  + each Gaussian can be expressed as x depends on $z_{k}$\n",
    "  $$p(x | z_{k} = 1) = N(x|\\mu_{k}, \\Sigma_{k})$$\n",
    "  and\n",
    "  $$p(x | Z) = \\prod_{k=1}^{K} N(x|\\mu_{k}, \\Sigma_{k})^{z_{k}}$$\n",
    "  + Marginal Distribution of x\n",
    "  $$p(x) = \\sum_{z} p(x|z) p(z) = \\sum_{k=1}^{K} \\pi_{k} N(x|\\mu_{k}, \\Sigma_{k})$$\n",
    "  + Responsity of a Gaussion\n",
    "  $$\\begin{aligned}\\gamma(z_{k}) \\equiv p(z_{k}=1|x) = \\frac{p(z_{k}=1)p(x|z_{k}=1)}{\\sum_{j=1}^{K} p(z_{j}=1)p(x|z_{j}=1)} \n",
    "     = \\frac{\\pi_{k}N(x|\\mu_{k}, \\Sigma_{k})}{\\sum_{j=1}^{K} \\pi_{j}N(x|\\mu_{j}, \\Sigma_{j})} \\end{aligned}$$\n",
    "  \n",
    "\n",
    "+ **EM**\n",
    "> + likelihood function\n",
    "    $$ p(X|\\pi, \\mu, \\Sigma) = \\prod_{n=1}^{N} p(x_{n}|\\pi,\\mu,\\Sigma) \n",
    "    = \\prod_{n=1}^{N}\\sum_{k=1}^{K}\\pi_{k}N(x_{n}|\\mu_{k}, \\Sigma_{k}) $$\n",
    "    Take log and get log-likelihood\n",
    "    $$\\ln p(X|\\pi, \\mu, \\Sigma) = \\sum_{n=1}^{N} \\ln \\bigg\\{ \\sum_{k=1}^{K}\\pi_{k}N(x_{n}|\\mu_{k}, \\Sigma_{k}) \\bigg\\} $$\n",
    "  + set Derivative of the log-likelihood w.r.t $\\pi$, $\\mu$, $\\Sigma$ to ***Zero*** <br/>\n",
    "    Since there is a constraint with $\\pi$: $\\sum_{\\pi_{k}}^{K} = 1$, we should use ***Langrange multiplier*** method.\n",
    "    >> + Derivative of log-likelihood w.r.t $\\mu_{k}$\n",
    "    $$N(x|\\mu, \\Sigma) = \\frac{1}{(2\\pi)^\\frac{D}{2}|\\Sigma|^{\\frac{1}{2}}} \n",
    "    exp\\bigg\\{ -\\frac{1}{2}(x-\\mu)^{T}\\Sigma^{-1}(x-\\mu)  \\bigg\\}$$\n",
    "    $$\\nabla_{\\mu_{k}} \\ln p(X|\\pi, \\mu, \\Sigma) = \n",
    "    \\sum_{n=1}^{N} \\frac{\\pi_{k}N(x_{n}|\\mu_{k}, \\Sigma_{k})}{\\Sigma_{j=1}^{K} \\pi_{j}N(x_{n}|\\mu_{j}, \\Sigma_{n})}\n",
    "    \\Sigma_{k}^{-1} (x_{n} - \\mu_{k}) = 0 $$    \n",
    "    $$\\mu_{k} = \\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma (z_{nk}) x_{n}$$\n",
    "    where $N_{k} = \\sum_{n=1}{N} \\gamma (z_{nk}) $\n",
    "    + Derivative w.r.t $\\Sigma_{k}$   \n",
    "    $$\\Sigma_{k} = \\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma(z_{nk}) (x_n-\\mu_k)(x_n-\\mu_k)^T$$\n",
    "\n",
    "    \n",
    "    \n",
    "         \n",
    "    \n",
    "  \n",
    "\n",
    "+ **VEM**\n",
    "> + Variational Method\n",
    "\n",
    "+ **Choose of Covariance** \n",
    "> + Diagonal\n",
    "> + Full\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This implementation only focus on diagonal Gaussians\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "class GMM:\n",
    "    def __init__(self):\n",
    "        EM_init()\n",
    "    \n",
    "    def Gauss(x, mu, Sigma):\n",
    "        \"\"\"Multivariate diagnal covariance Gaussian\"\"\"\n",
    "        return np.exp(-np.dot((x-mu)/Sigma, x-mu)) / (np.power(2 * np.pi, len(mu)/ 2) * np.sqrt(np.prod(Sigma)))\n",
    "\n",
    "    def log_likelihood(self, X):\n",
    "        \"\"\"Compute log likelihood\"\"\"\n",
    "        Mus, Pis, Sigmas = (self.Mus, self.Pis, self.Sigmas)\n",
    "        assert(len(Mus) == len(Pis)==len(Simgas))\n",
    "        K= len(Mus)\n",
    "        ll = np.sum(np.log(SumGauss(x, Mus, Pis, Sigmas)) for x in X)\n",
    "        return ll\n",
    "        \n",
    "        \n",
    "    def SumGauss(x, Mus, Sigmas, Pis):\n",
    "        return np.sum([Pis[i] * Gauss(x, Mus[i],Sigmas[i]) for i in range(len(Mus))])\n",
    "    \n",
    "    def EM_init(self, Mus, Sigmas, Pis):\n",
    "        \"\"\"Initialize EM\"\"\"\n",
    "        \n",
    "    def EM(X, Mus_init, Sigmas_init, Pis_init):\n",
    "        \"\"\"Expectation Maximization Algorithm\"\"\" \n",
    "        N = len(X)\n",
    "        # E-step\n",
    "        Mus, Sigmas, Pis = (Mus_init, Sigmas_init, Pis_init)\n",
    "        K = len(Mus)\n",
    "        def E(x, Mus, Sigmas, Pis):\n",
    "            g = SumGauss(x, Mus, Sigmas, Pis)\n",
    "            s = np.sum(g)\n",
    "            return g/s\n",
    "        \n",
    "        rk = np.array([E(x, Mus, Sigmas, Pis) for x in X])\n",
    "        Nk = np.sum(rk, axis=0)\n",
    "    \n",
    "        # M-step\n",
    "        Pis_new = Nk/N\n",
    "        Mus_new = np.array([np.sum([rk[n,k] * X[n] for n in range(0,N)], axis = 0) for k in range(0, K)])\n",
    "        def diag_M():\n",
    "            \n",
    "            \n",
    "            \n",
    "     \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def VEM():\n",
    "        \"\"\"Variational EM\"\"\"\n",
    "    \n",
    "    def GMM(data, K, covtype=\"diagonal\"):\n",
    "        \"\"\"Gaussian Mixture Model using Variational EM\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02185271,  2.97814729])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "d = 2\n",
    "Pis = np.array([.3,.3])\n",
    "Mus = np.array([[0.2, 0.7, 0.9], [2, 3, 4]])\n",
    "Sigmas = np.array([[0.4,.6, 0.7],[0.4,.3, 0.7]])\n",
    "\n",
    "def Gauss(x, mu, Sigma):\n",
    "    \"\"\"Multivariate diagnal covariance Gaussian\"\"\"\n",
    "    return np.exp(-np.dot((x-mu)/Sigma, x-mu)) / (np.power(2 * np.pi, len(mu)/ 2) * np.sqrt(np.prod(Sigma)))\n",
    "\n",
    "X=np.array([[1,2,3],[4,5,6],[7,9,8]])\n",
    "#g = [Pis[i] * Gauss(x, Mus[i],Sigmas[i]) for i in range(0, len(Mus))]\n",
    "#g1 = Gauss(x.reshape((3,1)), Mus[1].reshape((3,1)),Sigmas[1])\n",
    "#print(\"g1: \",g1)\n",
    "\n",
    "\n",
    "def E(x, Mus, Sigmas, Pis):\n",
    "        g = np.array([Pis[i] * Gauss(x, Mus[i],Sigmas[i]) for i in range(len(Mus))])\n",
    "        s = np.sum(g)\n",
    "        return g/s\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "rk = np.array([E(x, Mus, Sigmas, Pis) for x in X])\n",
    "nk = np.sum(rk, axis=0)\n",
    "nk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ab11875f3186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mGauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSigmas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-ab11875f3186>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mGauss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSigmas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "np.array([Pis[i] * Gauss(x, Mus[i],Sigmas[i]) for i in range(len(Mus))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 GMM in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn import mixture\n",
    "n_comp = 64\n",
    "gmm = mixture.GMM(n_components=n_comp, covariance_type='diag')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([1,2,3]) / (np.array([1,2,3]))).dot(np.array([1,2,3]))\n",
    "np.prod(np.array([1,2,3]))\n",
    "np.dot(np.array([1,2,3]).T, np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Hidden Markov Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
